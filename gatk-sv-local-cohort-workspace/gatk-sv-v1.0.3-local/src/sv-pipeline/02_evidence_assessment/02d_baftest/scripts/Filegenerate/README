# This part of the code generates a BAF file, a gzipped & tabix indexed file containing all BAF information needed for BAF analysis
# The inputs needed are 
#   1. A gzipped & tabix indexed vcf file (s3 bucket compatible)
#   2. A fasta.fai index file (can be the hg19 fai file, or if needed, select chromosomes), to split the genome into manageble chunks

# Step 1. Chunk the genome
# ```python /data/talkowski/hw878/PennCNV/BAFgeneration/BAF/BAFfilegenerate/File-generate/splitchr.py ${refdict} 500000 > chunk.txt```
# Result: chunk.txt

# Step 2. Extract BAF information from the chunks
# ```
#    tabix -h ${vcf} ${chr}:${start}-${end} | grep -E "^#|PASS"  |bcftools view -M2 -v snps - |python generate_baf.py > out.snp
# ```
# Result: out.snp (1 copy for each chunk, name is fixed for now)

# Step 3. Combine the BAF info chunks, gzip and index
# ```cat ${sep=" " bafs} > baf_snp.txt
#    sort -k1,1d -k2,2n baf_snp.txt>baf_snp_sorted.txt
#    bgzip baf_snp_sorted.txt
#    tabix -b2 baf_snp_sorted.txt.gz
# ```
# Result: baf_snp_sorted.txt.gz, baf_snp_sorted.txt.gz.tbi

# NOTE:
# Batch information & ID-swapping are currently disabled. Assuming the IDs stay consistent throughout analysis